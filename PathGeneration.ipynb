{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "JvPXIzWYxisA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "2Y9fa-qWxCuT"
      },
      "outputs": [],
      "source": [
        "def generate_paths_vectorized(vol_params, stock_params, num_steps, num_paths):\n",
        "    kappa, theta, sigma, rho, v0 = vol_params\n",
        "    S0, mu, T = stock_params\n",
        "    dt = T / num_steps\n",
        "    sqrt_dt = np.sqrt(dt)\n",
        "\n",
        "    # Preallocate\n",
        "    S = np.full(num_paths, S0)\n",
        "    v = np.full(num_paths, v0)\n",
        "\n",
        "    S_paths = np.zeros((num_steps + 1, num_paths))\n",
        "    v_paths = np.zeros((num_steps + 1, num_paths))\n",
        "\n",
        "    S_paths[0] = S\n",
        "    v_paths[0] = v\n",
        "\n",
        "    # Correlation matrix\n",
        "    corr = np.array([[1.0, rho], [rho, 1.0]])\n",
        "    L = np.linalg.cholesky(corr)\n",
        "\n",
        "    for t in range(1, num_steps + 1):\n",
        "        # Generate correlated normals for all paths at once\n",
        "        Z = np.random.normal(size=(2, num_paths))\n",
        "        Z = L @ Z\n",
        "        z1, z2 = Z\n",
        "\n",
        "        v_pos = np.maximum(v, 0.0)\n",
        "\n",
        "        # Vectorized variance update\n",
        "        v = v + kappa * (theta - v_pos) * dt + sigma * np.sqrt(v_pos) * sqrt_dt * z1\n",
        "        v = np.maximum(v, 0.0)\n",
        "\n",
        "        # Vectorized stock update\n",
        "        S = S + mu * S * dt + S * np.sqrt(v_pos) * sqrt_dt * z2\n",
        "\n",
        "        S_paths[t] = S\n",
        "        v_paths[t] = v\n",
        "\n",
        "    return S_paths.T, v_paths.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "ZyC4i0twyi2k"
      },
      "outputs": [],
      "source": [
        "vol_params = (25.0, 0.05, 0.3, -0.99, 0.01)\n",
        "stock_params = (100, 0.15, 1)\n",
        "\n",
        "S, v = generate_paths_vectorized(vol_params, stock_params, 200, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_features(S, v):\n",
        "    returns = np.log(S[:,1:] / S[:,:-1])\n",
        "    abs_returns = np.abs(returns)\n",
        "    square_returns = returns ** 2\n",
        "    v_shift = v[:, :-1]\n",
        "\n",
        "    return np.stack([returns, abs_returns, square_returns, v_shift], axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 200, 4)\n",
            "(1000, 200)\n"
          ]
        }
      ],
      "source": [
        "X = generate_features(S, v)\n",
        "\n",
        "y = (v[:, 1:] > v[:, :-1]).astype(int)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_sequences(data, labels, seq_len):\n",
        "    N, T, _ = data.shape\n",
        "\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    for p in range(N):\n",
        "        for t in range(T - seq_len):\n",
        "            X_list.append(data[p, t : t + seq_len])\n",
        "            y_list.append(labels[p, t + seq_len])\n",
        "    X = np.array(X_list)\n",
        "    y = np.array(y_list)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80000, 100, 4) (80000,)\n"
          ]
        }
      ],
      "source": [
        "X_train_seq, y_train_seq = make_sequences(X_train, y_train, 100) # sequence length 100\n",
        "X_test_seq, y_test_seq = make_sequences(X_test, y_test, 100)\n",
        "\n",
        "# rows = observed sequences\n",
        "# columns = entries in sequence\n",
        "# third axis = features\n",
        "print(X_train_seq.shape, y_train_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_2d = X_train_seq.reshape(-1, X_train.shape[-1])  # flatten time dimension\n",
        "X_test_2d = X_test_seq.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_2d).reshape(X_train_seq.shape)\n",
        "X_test_scaled = scaler.transform(X_test_2d).reshape(X_test_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {},
      "outputs": [],
      "source": [
        "# flat pack tensors\n",
        "xtrain_flat = X_train_scaled.reshape(80000, 400)\n",
        "xtest_flat = X_test_scaled.reshape(20000, 400)\n",
        "\n",
        "pd.DataFrame(xtrain_flat).to_csv('X_train.csv', index=None, columns=None)\n",
        "pd.DataFrame(xtest_flat).to_csv('X_test.csv', index=None, columns=None)\n",
        "\n",
        "pd.DataFrame(y_train_seq).to_csv('y_train.csv', index=None, columns=None)\n",
        "pd.DataFrame(y_test_seq).to_csv('y_test.csv', index=None, columns=None)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
